{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2022."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Data pipeline in TensorFlow: Columnar dataset processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "\n",
        "As comma-separated values (CSV) file format is the most popular file format for storing columnar data in data science, it is important to import data stored in a CSV file into TensorFlow. This tutorial will cover the basics of working with CSV files in TensorFlow through data pipeline API (`tf.data`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup and download data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrS6CbVZ5pYB"
      },
      "source": [
        "You can import TensorFlow into your program:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw__PMrO5qSf"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZmI7l_GykcW"
      },
      "source": [
        "The dataset used in this tutorial are taken from the Titanic passenger list. The labels are whether or not passengers survived and the characteristics like age, gender, ticket class, and whether the person was traveling alone are the features.\n",
        "\n",
        "For simplicity, the file is downloaded first:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpDC9OcSm5Sp"
      },
      "source": [
        "!curl -OL \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaJBZnTmnK9x"
      },
      "source": [
        "You can take a sneak preview of the data through command line `head train.csv`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzMMtUGAnTn7"
      },
      "source": [
        "!head -5 train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhRb1TMnncKD"
      },
      "source": [
        "|survived|sex|age|n_siblings_spouses|parch|fare|class|deck|embark_town|alone|\n",
        "|-|-|-|-|-|-|-|-|-|-|\n",
        "|0|male|22.0|1|0|7.25|Third|unknown|Southampton|n|\n",
        "|1|female|38.0|1|0|71.2833|First|C|Cherbourg|n|\n",
        "|1|female|26.0|0|0|7.925|Third|unknown|Southampton|y|\n",
        "|1|female|35.0|1|0|53.1|First|C|Southampton|n|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyrZVnRIS3ch"
      },
      "source": [
        "## Data processing with `tf.data.experimental.CsvDataset`\n",
        "\n",
        "The API of loading CSV into a `tf.data.Dataset` class is exposed through [tf.data.experimental.CsvDataset](https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset).\n",
        "\n",
        "There are many parameter arguments but only two are necessary: `filenames` is a tensor consists of one or more filenames of the CSV files, and `record_defaults` is a list of default values for the CSV fields. In addition, it is also useful to use `header=True` to skip the header line (first line), and use `select_cols` to only select the desired columns.\n",
        "\n",
        "Then with the following line you can load selected `survived, sex, age, fare`) into a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc4qLkq37lJq"
      },
      "source": [
        "dataset = tf.data.experimental.CsvDataset(\"train.csv\", [0, \"\", 0.0, 0.0], header=True, select_cols=[0, 1, 2, 5])\n",
        "\n",
        "print(\"dataset: {}\".format(dataset.element_spec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfesJ_VB8GlJ"
      },
      "source": [
        "The dataset is not very convinient as the name of the fields is not so obvious:\n",
        "\n",
        "```\n",
        "dataset: (\n",
        "  TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
        "  TensorSpec(shape=(), dtype=tf.string, name=None),\n",
        "  TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
        "  TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svZdDV2dscrz"
      },
      "source": [
        "We can use `map(func)` to convert the tuple of fields into a dict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUj0878jPyz7"
      },
      "source": [
        "def func(survived, sex, age, fare):\n",
        "  return {\"survived\": survived, \"sex\": sex, \"age\": age, \"fare\": fare}\n",
        "  \n",
        "dataset = dataset.map(func)\n",
        "\n",
        "print(\"dataset: {}\".format(dataset.element_spec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6qwJkYX82LS"
      },
      "source": [
        "The output is shown below:\n",
        "\n",
        "```\n",
        "dataset: {\n",
        "  'survived': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
        "  'sex': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
        "  'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
        "  'fare': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SklB4N-xERd"
      },
      "source": [
        "We can also `batch` the dataset at any time in order to group elements and potentially speed up the performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj0dWXwzxQW6"
      },
      "source": [
        "dataset = dataset.batch(1024)\n",
        "\n",
        "print(\"dataset: {}\".format(dataset.element_spec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Es3on5xZ6H"
      },
      "source": [
        "The fields of the batched dataset have the shape `(None,)` now:\n",
        "```\n",
        "dataset: {\n",
        "  'survived': TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n",
        "  'sex': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
        "  'age': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
        "  'fare': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViQ5TkouuZw"
      },
      "source": [
        "The categorical `sex` field could be converted into a numerical field with `map(func)` as well. Because the majority of the TensorFlow ops performs shape broadcast, you even don't need to worry about the shape `(None,)`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CNom1-nQGEW"
      },
      "source": [
        "def f(sex):\n",
        "  return tf.where(sex == \"female\", 1, 0)\n",
        "\n",
        "dataset = dataset.map(lambda e: {\"survived\": e[\"survived\"], \"sex\": f(e[\"sex\"]), \"age\": e[\"age\"], \"fare\": e[\"fare\"]})\n",
        "\n",
        "print(\"dataset: {}\".format(dataset.element_spec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFIMPrUrQdjy"
      },
      "source": [
        "Now the dataset's fields are much more friendly:\n",
        "\n",
        "```\n",
        "dataset: {\n",
        "  'survived': TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n",
        "  'sex': TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n",
        "  'age': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
        "  'fare': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZlj7VMjy87U"
      },
      "source": [
        "This tutorial shows many operations on top of `CsvDataset`. With those operations it is quite straightforward to import CSV data and construct a dataset that could be passed to succint `tf.keras` API, which will be very useful for data scientists to combine data with machine learning."
      ]
    }
  ]
}